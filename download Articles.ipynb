{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import requests\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver2 = webdriver.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2url = {\"2019\":\"https://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019\",\n",
    " \"2018\": \"https://papers.nips.cc/book/advances-in-neural-information-processing-systems-31-2018\",\n",
    " \"2017\": \"https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017\",\n",
    " \"2016\": \"https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\",\n",
    " \"2015\": \"https://papers.nips.cc/book/advances-in-neural-information-processing-systems-28-2015\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"22a2b3b64bb1c87b659a5e8ee601ebee\", element=\"c0758ad9-b5ef-4f71-ae71-24cbeed72141\")>\n",
      "Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim\n",
      "--------\n",
      "<selenium.webdriver.remote.webelement.WebElement (session=\"862e4ba07b90fdb804ea44e81a5f98e6\", element=\"e00b0d00-ba2e-41a9-a961-88442767cb68\")>\n",
      "Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization Francis Bach\n",
      "--------\n",
      "<selenium.webdriver.remote.webelement.WebElement (session=\"2514e0fabe38b1cd1d8d355cc309ef49\", element=\"7139f176-1f8e-4b8e-9243-3d5aa1c10b74\")>\n",
      "Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning Zhen He, Shaobing Gao, Liang Xiao, Daxue Liu, Hangen He, David Barber\n",
      "--------\n",
      "<selenium.webdriver.remote.webelement.WebElement (session=\"66631589bc81815c9790a0905714aa9b\", element=\"120a969b-2800-439c-bca8-1d93cc3ed643\")>\n",
      "Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much Bryan D. He, Christopher M. De Sa, Ioannis Mitliagkas, Christopher Ré\n",
      "--------\n",
      "<selenium.webdriver.remote.webelement.WebElement (session=\"e98d62f5bcfb1d7536d6fef9652534e9\", element=\"b19e442e-9e8c-4957-a379-bdc4191efc2a\")>\n",
      "Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing Nihar Bhadresh Shah, Dengyong Zhou\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "dataList = list()\n",
    "for y, url in year2url.items():\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver2 = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    data = downloadAllPaper(url, y)\n",
    "    dataList.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'2019_0': {'title': 'Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation',\n",
       "   'abstract': 'Model-agnostic meta-learners aim to acquire meta-learned parameters from similar tasks to adapt to novel tasks from the same distribution with few gradient updates. With the flexibility in the choice of models, those frameworks demonstrate appealing performance on a variety of domains such as few-shot image classification and reinforcement learning. However, one important limitation of such frameworks is that they seek a common initialization shared across the entire task distribution, substantially limiting the diversity of the task distributions that they are able to learn from. In this paper, we augment MAML with the capability to identify the mode of tasks sampled from a multimodal task distribution and adapt quickly through gradient updates. Specifically, we propose a multimodal MAML (MMAML) framework, which is able to modulate its meta-learned prior parameters according to the identified mode, allowing more efficient fast adaptation. We evaluate the proposed model on a diverse set of few-shot learning tasks, including regression, image classification, and reinforcement learning. The results not only demonstrate the effectiveness of our model in modulating the meta-learned prior in response to the characteristics of tasks but also show that training on a multimodal distribution can produce an improvement over unimodal training. The code for this project is publicly available at https://vuoristo.github.io/MMAML.',\n",
       "   'authors': ['Risto Vuorio',\n",
       "    'Shao-Hua Sun',\n",
       "    'Hexiang Hu',\n",
       "    'Joseph J. Lim']}},\n",
       " {'2018_0': {'title': 'Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization',\n",
       "   'abstract': 'We consider the minimization of submodular functions subject to ordering constraints. We show that this potentially non-convex optimization problem can be cast as a convex optimization problem on a space of uni-dimensional measures, with ordering constraints corresponding to first-order stochastic dominance. We propose new discretization schemes that lead to simple and efficient algorithms based on zero-th, first, or higher order oracles; these algorithms also lead to improvements without isotonic constraints. Finally, our experiments show that non-convex loss functions can be much more robust to outliers for isotonic regression, while still being solvable in polynomial time.',\n",
       "   'authors': ['Francis Bach']}},\n",
       " {'2017_0': {'title': 'Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning',\n",
       "   'abstract': 'Long Short-Term Memory (LSTM) is a popular approach to boosting the ability of Recurrent Neural Networks to store longer term temporal information. The capacity of an LSTM network can be increased by widening and adding layers. However, usually the former introduces additional parameters, while the latter increases the runtime. As an alternative we propose the Tensorized LSTM in which the hidden states are represented by tensors and updated via a cross-layer convolution. By increasing the tensor size, the network can be widened efficiently without additional parameters since the parameters are shared across different locations in the tensor; by delaying the output, the network can be deepened implicitly with little additional runtime since deep computations for each timestep are merged into temporal computations of the sequence. Experiments conducted on five challenging sequence learning tasks show the potential of the proposed model.',\n",
       "   'authors': ['Zhen He',\n",
       "    'Shaobing Gao',\n",
       "    'Liang Xiao',\n",
       "    'Daxue Liu',\n",
       "    'Hangen He',\n",
       "    'David Barber']}},\n",
       " {'2016_0': {'title': 'Scan Order in Gibbs Sampling: Models in Which it Matters and Bounds on How Much',\n",
       "   'abstract': 'Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance.',\n",
       "   'authors': ['Bryan D. He',\n",
       "    'Christopher M. De Sa',\n",
       "    'Ioannis Mitliagkas',\n",
       "    'Christopher Ré']}},\n",
       " {'2015_0': {'title': 'Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing',\n",
       "   'abstract': 'Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural no-free-lunch requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentive-compatible mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers. Interestingly, this unique mechanism takes a multiplicative form. The simplicity of the mechanism is an added benefit. In preliminary experiments involving over several hundred workers, we observe a significant reduction in the error rates under our unique mechanism for the same or lower monetary expenditure.',\n",
       "   'authors': ['Nihar Bhadresh Shah', 'Dengyong Zhou']}}]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "for d in dataList:\n",
    "    result.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(result, open('/hdd/dataPhdProject/dataDict', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadAllPaper(mainUrl, year):\n",
    "    did2data = {}\n",
    "    \n",
    "    \n",
    "    driver.get(mainUrl)\n",
    "    ulElements = driver.find_elements_by_tag_name(\"ul\")\n",
    "    ul = ulElements[1]\n",
    "    liElemetns = ul.find_elements_by_tag_name(\"li\")\n",
    "    \n",
    "    for i, li in enumerate(liElemetns):\n",
    "        did = str(year) + \"_\"+ str(i)\n",
    "        \n",
    "        print(li)\n",
    "        print(li.text)\n",
    "        print(\"--------\")\n",
    "        \n",
    "        aElements = li.find_element_by_tag_name(\"a\")\n",
    "\n",
    "        paperUrl = aElements.get_attribute('href')\n",
    "        did2data[did] = downloadPaperData(did, paperUrl)\n",
    "        time.sleep(0.2)\n",
    "        break\n",
    "        \n",
    "    return did2data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"77a16da459ef029ca3af6b770395b716\", element=\"2b671750-7c48-4085-af93-f31eab24d13c\")>\n",
      "Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation Risto Vuorio, Shao-Hua Sun, Hexiang Hu, Joseph J. Lim\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "X = downloadAllPaper(nip2019, \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2019_0': {'title': 'Multimodal Model-Agnostic Meta-Learning via Task-Aware Modulation',\n",
       "  'abstract': 'Model-agnostic meta-learners aim to acquire meta-learned parameters from similar tasks to adapt to novel tasks from the same distribution with few gradient updates. With the flexibility in the choice of models, those frameworks demonstrate appealing performance on a variety of domains such as few-shot image classification and reinforcement learning. However, one important limitation of such frameworks is that they seek a common initialization shared across the entire task distribution, substantially limiting the diversity of the task distributions that they are able to learn from. In this paper, we augment MAML with the capability to identify the mode of tasks sampled from a multimodal task distribution and adapt quickly through gradient updates. Specifically, we propose a multimodal MAML (MMAML) framework, which is able to modulate its meta-learned prior parameters according to the identified mode, allowing more efficient fast adaptation. We evaluate the proposed model on a diverse set of few-shot learning tasks, including regression, image classification, and reinforcement learning. The results not only demonstrate the effectiveness of our model in modulating the meta-learned prior in response to the characteristics of tasks but also show that training on a multimodal distribution can produce an improvement over unimodal training. The code for this project is publicly available at https://vuoristo.github.io/MMAML.',\n",
       "  'authors': ['Risto Vuorio', 'Shao-Hua Sun', 'Hexiang Hu', 'Joseph J. Lim']}}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadPaperData(did, url):\n",
    "    \n",
    "    driver2.get(url)\n",
    "    title = driver2.find_element_by_class_name(\"subtitle\").text\n",
    "    abstract = driver2.find_element_by_class_name(\"abstract\").text\n",
    "    authors = getAuthors()\n",
    "    downloadPdf(did)\n",
    "    \n",
    "    return {\"title\":title, \"abstract\":abstract, \"authors\":authors}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuthors():\n",
    "    ulElements = driver2.find_elements_by_tag_name(\"ul\")\n",
    "    ul = ulElements[1]\n",
    "    \n",
    "    liElemetns = ul.find_elements_by_tag_name(\"li\")\n",
    "    \n",
    "    authors = list()\n",
    "    for li in liElemetns:\n",
    "        authors.append(li.find_element_by_tag_name(\"a\").text)\n",
    "    return authors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadPdf(did):\n",
    "    url = None\n",
    "    aTags = driver2.find_elements_by_tag_name(\"a\")\n",
    "    for a in aTags:\n",
    "        if a.text == \"[PDF]\":\n",
    "            url = a.get_attribute('href')\n",
    "    \n",
    "    if url:\n",
    "        response = requests.get(url)\n",
    "        with open('/hdd/dataPhdProject/{}.pdf'.format(did), 'wb') as f:\n",
    "            f.write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BERTmodel\t\t\t     diva2019\t     lost+found\r\n",
      "'DiVA-data - KTH_s platformar.zip'   diva_2004\t     temp\r\n",
      " dataX.zip\t\t\t     diva_2004.zip   terranData\r\n",
      " dataframes\t\t\t     diva_olds\t     terranDataFrontend\r\n"
     ]
    }
   ],
   "source": [
    "!ls /hdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (terran3)",
   "language": "python",
   "name": "terran3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
